{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'official'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-dfc44a710a8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtext_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilders\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_builder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilders\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_builder_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Dektop\\Git projects\\MazeSolverCV\\object_detection\\builders\\model_builder.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrfcn_keras_box_predictor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mssd_efficientnet_bifpn_feature_extractor\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mssd_efficientnet_bifpn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtf_version\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_tf1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Dektop\\Git projects\\MazeSolverCV\\object_detection\\models\\ssd_efficientnet_bifpn_feature_extractor.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtf_version\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_tf2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mofficial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_classification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mefficientnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mefficientnet_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m _EFFICIENTNET_LEVEL_ENDPOINTS = {\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'official'"
     ]
    }
   ],
   "source": [
    "# Lint as: python2, python3\n",
    "# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Tests for model_builder under TensorFlow 2.X.\"\"\"\n",
    "\n",
    "import os\n",
    "import unittest\n",
    "\n",
    "from absl.testing import parameterized\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "from google.protobuf import text_format\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.builders import model_builder_test\n",
    "from object_detection.core import losses\n",
    "from object_detection.meta_architectures import deepmac_meta_arch\n",
    "from object_detection.models import center_net_hourglass_feature_extractor\n",
    "from object_detection.models.keras_models import hourglass_network\n",
    "from object_detection.protos import center_net_pb2\n",
    "from object_detection.protos import model_pb2\n",
    "from object_detection.utils import tf_version\n",
    "\n",
    "\n",
    "@unittest.skipIf(tf_version.is_tf1(), 'Skipping TF2.X only test.')\n",
    "class ModelBuilderTF2Test(\n",
    "    model_builder_test.ModelBuilderTest, parameterized.TestCase):\n",
    "\n",
    "  def default_ssd_feature_extractor(self):\n",
    "    return 'ssd_resnet50_v1_fpn_keras'\n",
    "\n",
    "  def default_faster_rcnn_feature_extractor(self):\n",
    "    return 'faster_rcnn_resnet101_keras'\n",
    "\n",
    "  def ssd_feature_extractors(self):\n",
    "    return model_builder.SSD_KERAS_FEATURE_EXTRACTOR_CLASS_MAP\n",
    "\n",
    "  def get_override_base_feature_extractor_hyperparams(self, extractor_type):\n",
    "    return extractor_type in {}\n",
    "\n",
    "  def faster_rcnn_feature_extractors(self):\n",
    "    return model_builder.FASTER_RCNN_KERAS_FEATURE_EXTRACTOR_CLASS_MAP\n",
    "\n",
    "  def get_fake_label_map_file_path(self):\n",
    "    keypoint_spec_text = \"\"\"\n",
    "    item {\n",
    "      name: \"/m/01g317\"\n",
    "      id: 1\n",
    "      display_name: \"person\"\n",
    "      keypoints {\n",
    "        id: 0\n",
    "        label: 'nose'\n",
    "      }\n",
    "      keypoints {\n",
    "        id: 1\n",
    "        label: 'left_shoulder'\n",
    "      }\n",
    "      keypoints {\n",
    "        id: 2\n",
    "        label: 'right_shoulder'\n",
    "      }\n",
    "      keypoints {\n",
    "        id: 3\n",
    "        label: 'hip'\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "    keypoint_label_map_path = os.path.join(\n",
    "        self.get_temp_dir(), 'keypoint_label_map')\n",
    "    with tf.gfile.Open(keypoint_label_map_path, 'wb') as f:\n",
    "      f.write(keypoint_spec_text)\n",
    "    return keypoint_label_map_path\n",
    "\n",
    "  def get_fake_keypoint_proto(self, customize_head_params=False):\n",
    "    task_proto_txt = \"\"\"\n",
    "      task_name: \"human_pose\"\n",
    "      task_loss_weight: 0.9\n",
    "      keypoint_regression_loss_weight: 1.0\n",
    "      keypoint_heatmap_loss_weight: 0.1\n",
    "      keypoint_offset_loss_weight: 0.5\n",
    "      heatmap_bias_init: 2.14\n",
    "      keypoint_class_name: \"/m/01g317\"\n",
    "      loss {\n",
    "        classification_loss {\n",
    "          penalty_reduced_logistic_focal_loss {\n",
    "            alpha: 3.0\n",
    "            beta: 4.0\n",
    "          }\n",
    "        }\n",
    "        localization_loss {\n",
    "          l1_localization_loss {\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "      keypoint_label_to_std {\n",
    "        key: \"nose\"\n",
    "        value: 0.3\n",
    "      }\n",
    "      keypoint_label_to_std {\n",
    "        key: \"hip\"\n",
    "        value: 0.0\n",
    "      }\n",
    "      keypoint_candidate_score_threshold: 0.3\n",
    "      num_candidates_per_keypoint: 12\n",
    "      peak_max_pool_kernel_size: 5\n",
    "      unmatched_keypoint_score: 0.05\n",
    "      box_scale: 1.7\n",
    "      candidate_search_scale: 0.2\n",
    "      candidate_ranking_mode: \"score_distance_ratio\"\n",
    "      offset_peak_radius: 3\n",
    "      per_keypoint_offset: true\n",
    "      predict_depth: true\n",
    "      per_keypoint_depth: true\n",
    "      keypoint_depth_loss_weight: 0.3\n",
    "      score_distance_multiplier: 11.0\n",
    "      std_dev_multiplier: 2.8\n",
    "      rescoring_threshold: 0.5\n",
    "      gaussian_denom_ratio: 0.3\n",
    "      argmax_postprocessing: True\n",
    "    \"\"\"\n",
    "    if customize_head_params:\n",
    "      task_proto_txt += \"\"\"\n",
    "      heatmap_head_params {\n",
    "        num_filters: 64\n",
    "        num_filters: 32\n",
    "        kernel_sizes: 5\n",
    "        kernel_sizes: 3\n",
    "      }\n",
    "      offset_head_params {\n",
    "        num_filters: 128\n",
    "        num_filters: 64\n",
    "        kernel_sizes: 5\n",
    "        kernel_sizes: 3\n",
    "      }\n",
    "      \"\"\"\n",
    "    config = text_format.Merge(task_proto_txt,\n",
    "                               center_net_pb2.CenterNet.KeypointEstimation())\n",
    "    return config\n",
    "\n",
    "  def get_fake_object_center_proto(self, customize_head_params=False):\n",
    "    proto_txt = \"\"\"\n",
    "      object_center_loss_weight: 0.5\n",
    "      heatmap_bias_init: 3.14\n",
    "      min_box_overlap_iou: 0.2\n",
    "      max_box_predictions: 15\n",
    "      classification_loss {\n",
    "        penalty_reduced_logistic_focal_loss {\n",
    "          alpha: 3.0\n",
    "          beta: 4.0\n",
    "        }\n",
    "      }\n",
    "      peak_max_pool_kernel_size: 5\n",
    "    \"\"\"\n",
    "    if customize_head_params:\n",
    "      proto_txt += \"\"\"\n",
    "      center_head_params {\n",
    "        num_filters: 64\n",
    "        num_filters: 32\n",
    "        kernel_sizes: 5\n",
    "        kernel_sizes: 3\n",
    "      }\n",
    "      \"\"\"\n",
    "    return text_format.Merge(proto_txt,\n",
    "                             center_net_pb2.CenterNet.ObjectCenterParams())\n",
    "\n",
    "  def get_fake_object_center_from_keypoints_proto(self):\n",
    "    proto_txt = \"\"\"\n",
    "      object_center_loss_weight: 0.5\n",
    "      heatmap_bias_init: 3.14\n",
    "      min_box_overlap_iou: 0.2\n",
    "      max_box_predictions: 15\n",
    "      classification_loss {\n",
    "        penalty_reduced_logistic_focal_loss {\n",
    "          alpha: 3.0\n",
    "          beta: 4.0\n",
    "        }\n",
    "      }\n",
    "      keypoint_weights_for_center: 1.0\n",
    "      keypoint_weights_for_center: 0.0\n",
    "      keypoint_weights_for_center: 1.0\n",
    "      keypoint_weights_for_center: 0.0\n",
    "    \"\"\"\n",
    "    return text_format.Merge(proto_txt,\n",
    "                             center_net_pb2.CenterNet.ObjectCenterParams())\n",
    "\n",
    "  def get_fake_object_detection_proto(self, customize_head_params=False):\n",
    "    proto_txt = \"\"\"\n",
    "      task_loss_weight: 0.5\n",
    "      offset_loss_weight: 0.1\n",
    "      scale_loss_weight: 0.2\n",
    "      localization_loss {\n",
    "        l1_localization_loss {\n",
    "        }\n",
    "      }\n",
    "    \"\"\"\n",
    "    if customize_head_params:\n",
    "      proto_txt += \"\"\"\n",
    "      scale_head_params {\n",
    "        num_filters: 128\n",
    "        num_filters: 64\n",
    "        kernel_sizes: 5\n",
    "        kernel_sizes: 3\n",
    "      }\n",
    "    \"\"\"\n",
    "    return text_format.Merge(proto_txt,\n",
    "                             center_net_pb2.CenterNet.ObjectDetection())\n",
    "\n",
    "  def get_fake_mask_proto(self, customize_head_params=False):\n",
    "    proto_txt = \"\"\"\n",
    "      task_loss_weight: 0.7\n",
    "      classification_loss {\n",
    "        weighted_softmax {}\n",
    "      }\n",
    "      mask_height: 8\n",
    "      mask_width: 8\n",
    "      score_threshold: 0.7\n",
    "      heatmap_bias_init: -2.0\n",
    "    \"\"\"\n",
    "    if customize_head_params:\n",
    "      proto_txt += \"\"\"\n",
    "      mask_head_params {\n",
    "        num_filters: 128\n",
    "        num_filters: 64\n",
    "        kernel_sizes: 5\n",
    "        kernel_sizes: 3\n",
    "      }\n",
    "    \"\"\"\n",
    "    return text_format.Merge(proto_txt,\n",
    "                             center_net_pb2.CenterNet.MaskEstimation())\n",
    "\n",
    "  def get_fake_densepose_proto(self):\n",
    "    proto_txt = \"\"\"\n",
    "      task_loss_weight: 0.5\n",
    "      class_id: 0\n",
    "      loss {\n",
    "        classification_loss {\n",
    "          weighted_softmax {}\n",
    "        }\n",
    "        localization_loss {\n",
    "          l1_localization_loss {\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "      num_parts: 24\n",
    "      part_loss_weight: 1.0\n",
    "      coordinate_loss_weight: 2.0\n",
    "      upsample_to_input_res: true\n",
    "      heatmap_bias_init: -2.0\n",
    "    \"\"\"\n",
    "    return text_format.Merge(proto_txt,\n",
    "                             center_net_pb2.CenterNet.DensePoseEstimation())\n",
    "\n",
    "  @parameterized.parameters(\n",
    "      {'customize_head_params': True},\n",
    "      {'customize_head_params': False}\n",
    "  )\n",
    "  def test_create_center_net_model(self, customize_head_params):\n",
    "    \"\"\"Test building a CenterNet model from proto txt.\"\"\"\n",
    "    proto_txt = \"\"\"\n",
    "      center_net {\n",
    "        num_classes: 10\n",
    "        feature_extractor {\n",
    "          type: \"hourglass_52\"\n",
    "          channel_stds: [4, 5, 6]\n",
    "          bgr_ordering: true\n",
    "        }\n",
    "        image_resizer {\n",
    "          keep_aspect_ratio_resizer {\n",
    "            min_dimension: 512\n",
    "            max_dimension: 512\n",
    "            pad_to_max_dimension: true\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    \"\"\"\n",
    "    # Set up the configuration proto.\n",
    "    config = text_format.Merge(proto_txt, model_pb2.DetectionModel())\n",
    "    config.center_net.object_center_params.CopyFrom(\n",
    "        self.get_fake_object_center_proto(\n",
    "            customize_head_params=customize_head_params))\n",
    "    config.center_net.object_detection_task.CopyFrom(\n",
    "        self.get_fake_object_detection_proto(\n",
    "            customize_head_params=customize_head_params))\n",
    "    config.center_net.keypoint_estimation_task.append(\n",
    "        self.get_fake_keypoint_proto(\n",
    "            customize_head_params=customize_head_params))\n",
    "    config.center_net.keypoint_label_map_path = (\n",
    "        self.get_fake_label_map_file_path())\n",
    "    config.center_net.mask_estimation_task.CopyFrom(\n",
    "        self.get_fake_mask_proto(\n",
    "            customize_head_params=customize_head_params))\n",
    "    config.center_net.densepose_estimation_task.CopyFrom(\n",
    "        self.get_fake_densepose_proto())\n",
    "\n",
    "    # Build the model from the configuration.\n",
    "    model = model_builder.build(config, is_training=True)\n",
    "\n",
    "    # Check object center related parameters.\n",
    "    self.assertEqual(model._num_classes, 10)\n",
    "    self.assertIsInstance(model._center_params.classification_loss,\n",
    "                          losses.PenaltyReducedLogisticFocalLoss)\n",
    "    self.assertEqual(model._center_params.classification_loss._alpha, 3.0)\n",
    "    self.assertEqual(model._center_params.classification_loss._beta, 4.0)\n",
    "    self.assertAlmostEqual(model._center_params.min_box_overlap_iou, 0.2)\n",
    "    self.assertAlmostEqual(\n",
    "        model._center_params.heatmap_bias_init, 3.14, places=4)\n",
    "    self.assertEqual(model._center_params.max_box_predictions, 15)\n",
    "    if customize_head_params:\n",
    "      self.assertEqual(model._center_params.center_head_num_filters, [64, 32])\n",
    "      self.assertEqual(model._center_params.center_head_kernel_sizes, [5, 3])\n",
    "    else:\n",
    "      self.assertEqual(model._center_params.center_head_num_filters, [256])\n",
    "      self.assertEqual(model._center_params.center_head_kernel_sizes, [3])\n",
    "    self.assertEqual(model._center_params.peak_max_pool_kernel_size, 5)\n",
    "\n",
    "    # Check object detection related parameters.\n",
    "    self.assertAlmostEqual(model._od_params.offset_loss_weight, 0.1)\n",
    "    self.assertAlmostEqual(model._od_params.scale_loss_weight, 0.2)\n",
    "    self.assertAlmostEqual(model._od_params.task_loss_weight, 0.5)\n",
    "    self.assertIsInstance(model._od_params.localization_loss,\n",
    "                          losses.L1LocalizationLoss)\n",
    "    self.assertEqual(model._od_params.offset_head_num_filters, [256])\n",
    "    self.assertEqual(model._od_params.offset_head_kernel_sizes, [3])\n",
    "    if customize_head_params:\n",
    "      self.assertEqual(model._od_params.scale_head_num_filters, [128, 64])\n",
    "      self.assertEqual(model._od_params.scale_head_kernel_sizes, [5, 3])\n",
    "    else:\n",
    "      self.assertEqual(model._od_params.scale_head_num_filters, [256])\n",
    "      self.assertEqual(model._od_params.scale_head_kernel_sizes, [3])\n",
    "\n",
    "    # Check keypoint estimation related parameters.\n",
    "    kp_params = model._kp_params_dict['human_pose']\n",
    "    self.assertAlmostEqual(kp_params.task_loss_weight, 0.9)\n",
    "    self.assertAlmostEqual(kp_params.keypoint_regression_loss_weight, 1.0)\n",
    "    self.assertAlmostEqual(kp_params.keypoint_offset_loss_weight, 0.5)\n",
    "    self.assertAlmostEqual(kp_params.heatmap_bias_init, 2.14, places=4)\n",
    "    self.assertEqual(kp_params.classification_loss._alpha, 3.0)\n",
    "    self.assertEqual(kp_params.keypoint_indices, [0, 1, 2, 3])\n",
    "    self.assertEqual(kp_params.keypoint_labels,\n",
    "                     ['nose', 'left_shoulder', 'right_shoulder', 'hip'])\n",
    "    self.assertAllClose(kp_params.keypoint_std_dev, [0.3, 1.0, 1.0, 0.0])\n",
    "    self.assertEqual(kp_params.classification_loss._beta, 4.0)\n",
    "    self.assertIsInstance(kp_params.localization_loss,\n",
    "                          losses.L1LocalizationLoss)\n",
    "    self.assertAlmostEqual(kp_params.keypoint_candidate_score_threshold, 0.3)\n",
    "    self.assertEqual(kp_params.num_candidates_per_keypoint, 12)\n",
    "    self.assertEqual(kp_params.peak_max_pool_kernel_size, 5)\n",
    "    self.assertAlmostEqual(kp_params.unmatched_keypoint_score, 0.05)\n",
    "    self.assertAlmostEqual(kp_params.box_scale, 1.7)\n",
    "    self.assertAlmostEqual(kp_params.candidate_search_scale, 0.2)\n",
    "    self.assertEqual(kp_params.candidate_ranking_mode, 'score_distance_ratio')\n",
    "    self.assertEqual(kp_params.offset_peak_radius, 3)\n",
    "    self.assertEqual(kp_params.per_keypoint_offset, True)\n",
    "    self.assertEqual(kp_params.predict_depth, True)\n",
    "    self.assertEqual(kp_params.per_keypoint_depth, True)\n",
    "    self.assertAlmostEqual(kp_params.keypoint_depth_loss_weight, 0.3)\n",
    "    self.assertAlmostEqual(kp_params.score_distance_multiplier, 11.0)\n",
    "    self.assertAlmostEqual(kp_params.std_dev_multiplier, 2.8)\n",
    "    self.assertAlmostEqual(kp_params.rescoring_threshold, 0.5)\n",
    "    if customize_head_params:\n",
    "      # Set by the config.\n",
    "      self.assertEqual(kp_params.heatmap_head_num_filters, [64, 32])\n",
    "      self.assertEqual(kp_params.heatmap_head_kernel_sizes, [5, 3])\n",
    "      self.assertEqual(kp_params.offset_head_num_filters, [128, 64])\n",
    "      self.assertEqual(kp_params.offset_head_kernel_sizes, [5, 3])\n",
    "    else:\n",
    "      # Default values:\n",
    "      self.assertEqual(kp_params.heatmap_head_num_filters, [256])\n",
    "      self.assertEqual(kp_params.heatmap_head_kernel_sizes, [3])\n",
    "      self.assertEqual(kp_params.offset_head_num_filters, [256])\n",
    "      self.assertEqual(kp_params.offset_head_kernel_sizes, [3])\n",
    "    self.assertAlmostEqual(kp_params.gaussian_denom_ratio, 0.3)\n",
    "    self.assertEqual(kp_params.argmax_postprocessing, True)\n",
    "\n",
    "    # Check mask related parameters.\n",
    "    self.assertAlmostEqual(model._mask_params.task_loss_weight, 0.7)\n",
    "    self.assertIsInstance(model._mask_params.classification_loss,\n",
    "                          losses.WeightedSoftmaxClassificationLoss)\n",
    "    self.assertEqual(model._mask_params.mask_height, 8)\n",
    "    self.assertEqual(model._mask_params.mask_width, 8)\n",
    "    self.assertAlmostEqual(model._mask_params.score_threshold, 0.7)\n",
    "    self.assertAlmostEqual(\n",
    "        model._mask_params.heatmap_bias_init, -2.0, places=4)\n",
    "    if customize_head_params:\n",
    "      self.assertEqual(model._mask_params.mask_head_num_filters, [128, 64])\n",
    "      self.assertEqual(model._mask_params.mask_head_kernel_sizes, [5, 3])\n",
    "    else:\n",
    "      self.assertEqual(model._mask_params.mask_head_num_filters, [256])\n",
    "      self.assertEqual(model._mask_params.mask_head_kernel_sizes, [3])\n",
    "\n",
    "    # Check DensePose related parameters.\n",
    "    self.assertEqual(model._densepose_params.class_id, 0)\n",
    "    self.assertIsInstance(model._densepose_params.classification_loss,\n",
    "                          losses.WeightedSoftmaxClassificationLoss)\n",
    "    self.assertIsInstance(model._densepose_params.localization_loss,\n",
    "                          losses.L1LocalizationLoss)\n",
    "    self.assertAlmostEqual(model._densepose_params.part_loss_weight, 1.0)\n",
    "    self.assertAlmostEqual(model._densepose_params.coordinate_loss_weight, 2.0)\n",
    "    self.assertEqual(model._densepose_params.num_parts, 24)\n",
    "    self.assertAlmostEqual(model._densepose_params.task_loss_weight, 0.5)\n",
    "    self.assertTrue(model._densepose_params.upsample_to_input_res)\n",
    "    self.assertEqual(model._densepose_params.upsample_method, 'bilinear')\n",
    "    self.assertAlmostEqual(\n",
    "        model._densepose_params.heatmap_bias_init, -2.0, places=4)\n",
    "\n",
    "    # Check feature extractor parameters.\n",
    "    self.assertIsInstance(\n",
    "        model._feature_extractor, center_net_hourglass_feature_extractor\n",
    "        .CenterNetHourglassFeatureExtractor)\n",
    "    self.assertAllClose(model._feature_extractor._channel_means, [0, 0, 0])\n",
    "    self.assertAllClose(model._feature_extractor._channel_stds, [4, 5, 6])\n",
    "    self.assertTrue(model._feature_extractor._bgr_ordering)\n",
    "    backbone = model._feature_extractor._network\n",
    "    self.assertIsInstance(backbone, hourglass_network.HourglassNetwork)\n",
    "    self.assertTrue(backbone.num_hourglasses, 1)\n",
    "\n",
    "  def test_create_center_net_model_from_keypoints(self):\n",
    "    \"\"\"Test building a CenterNet model from proto txt.\"\"\"\n",
    "    proto_txt = \"\"\"\n",
    "      center_net {\n",
    "        num_classes: 10\n",
    "        feature_extractor {\n",
    "          type: \"hourglass_52\"\n",
    "          channel_stds: [4, 5, 6]\n",
    "          bgr_ordering: true\n",
    "        }\n",
    "        image_resizer {\n",
    "          keep_aspect_ratio_resizer {\n",
    "            min_dimension: 512\n",
    "            max_dimension: 512\n",
    "            pad_to_max_dimension: true\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    \"\"\"\n",
    "    # Set up the configuration proto.\n",
    "    config = text_format.Parse(proto_txt, model_pb2.DetectionModel())\n",
    "    # Only add object center and keypoint estimation configs here.\n",
    "    config.center_net.object_center_params.CopyFrom(\n",
    "        self.get_fake_object_center_from_keypoints_proto())\n",
    "    config.center_net.keypoint_estimation_task.append(\n",
    "        self.get_fake_keypoint_proto())\n",
    "    config.center_net.keypoint_label_map_path = (\n",
    "        self.get_fake_label_map_file_path())\n",
    "\n",
    "    # Build the model from the configuration.\n",
    "    model = model_builder.build(config, is_training=True)\n",
    "\n",
    "    # Check object center related parameters.\n",
    "    self.assertEqual(model._num_classes, 10)\n",
    "    self.assertEqual(model._center_params.keypoint_weights_for_center,\n",
    "                     [1.0, 0.0, 1.0, 0.0])\n",
    "\n",
    "    # Check keypoint estimation related parameters.\n",
    "    kp_params = model._kp_params_dict['human_pose']\n",
    "    self.assertAlmostEqual(kp_params.task_loss_weight, 0.9)\n",
    "    self.assertEqual(kp_params.keypoint_indices, [0, 1, 2, 3])\n",
    "    self.assertEqual(kp_params.keypoint_labels,\n",
    "                     ['nose', 'left_shoulder', 'right_shoulder', 'hip'])\n",
    "\n",
    "  def test_create_center_net_model_mobilenet(self):\n",
    "    \"\"\"Test building a CenterNet model using bilinear interpolation.\"\"\"\n",
    "    proto_txt = \"\"\"\n",
    "      center_net {\n",
    "        num_classes: 10\n",
    "        feature_extractor {\n",
    "          type: \"mobilenet_v2_fpn\"\n",
    "          depth_multiplier: 2.0\n",
    "          use_separable_conv: true\n",
    "          upsampling_interpolation: \"bilinear\"\n",
    "        }\n",
    "        image_resizer {\n",
    "          keep_aspect_ratio_resizer {\n",
    "            min_dimension: 512\n",
    "            max_dimension: 512\n",
    "            pad_to_max_dimension: true\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    \"\"\"\n",
    "    # Set up the configuration proto.\n",
    "    config = text_format.Parse(proto_txt, model_pb2.DetectionModel())\n",
    "    # Only add object center and keypoint estimation configs here.\n",
    "    config.center_net.object_center_params.CopyFrom(\n",
    "        self.get_fake_object_center_from_keypoints_proto())\n",
    "    config.center_net.keypoint_estimation_task.append(\n",
    "        self.get_fake_keypoint_proto())\n",
    "    config.center_net.keypoint_label_map_path = (\n",
    "        self.get_fake_label_map_file_path())\n",
    "\n",
    "    # Build the model from the configuration.\n",
    "    model = model_builder.build(config, is_training=True)\n",
    "\n",
    "    feature_extractor = model._feature_extractor\n",
    "    # Verify the upsampling layers in the FPN use 'bilinear' interpolation.\n",
    "    fpn = feature_extractor.get_layer('model_1')\n",
    "    num_up_sampling2d_layers = 0\n",
    "    for layer in fpn.layers:\n",
    "      if 'up_sampling2d' in layer.name:\n",
    "        num_up_sampling2d_layers += 1\n",
    "        self.assertEqual('bilinear', layer.interpolation)\n",
    "    # Verify that there are up_sampling2d layers.\n",
    "    self.assertGreater(num_up_sampling2d_layers, 0)\n",
    "\n",
    "    # Verify that the FPN ops uses separable conv.\n",
    "    for layer in fpn.layers:\n",
    "      # Convolution layers with kernel size not equal to (1, 1) should be\n",
    "      # separable 2D convolutions.\n",
    "      if 'conv' in layer.name and layer.kernel_size != (1, 1):\n",
    "        self.assertIsInstance(layer, tf.keras.layers.SeparableConv2D)\n",
    "\n",
    "    # Verify that the backbone indeed double the number of channel according to\n",
    "    # the depthmultiplier.\n",
    "    backbone = feature_extractor.get_layer('model')\n",
    "    first_conv = backbone.get_layer('Conv1')\n",
    "    # Note that the first layer typically has 32 filters, but this model has\n",
    "    # a depth multiplier of 2.\n",
    "    self.assertEqual(64, first_conv.filters)\n",
    "\n",
    "  def test_create_center_net_deepmac(self):\n",
    "    \"\"\"Test building a CenterNet DeepMAC model.\"\"\"\n",
    "\n",
    "    proto_txt = \"\"\"\n",
    "      center_net {\n",
    "        num_classes: 90\n",
    "        feature_extractor {\n",
    "          type: \"hourglass_52\"\n",
    "        }\n",
    "        image_resizer {\n",
    "          keep_aspect_ratio_resizer {\n",
    "            min_dimension: 512\n",
    "            max_dimension: 512\n",
    "            pad_to_max_dimension: true\n",
    "          }\n",
    "        }\n",
    "        object_detection_task {\n",
    "          task_loss_weight: 1.0\n",
    "          offset_loss_weight: 1.0\n",
    "          scale_loss_weight: 0.1\n",
    "          localization_loss {\n",
    "            l1_localization_loss {\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "        object_center_params {\n",
    "          object_center_loss_weight: 1.0\n",
    "          min_box_overlap_iou: 0.7\n",
    "          max_box_predictions: 100\n",
    "          classification_loss {\n",
    "            penalty_reduced_logistic_focal_loss {\n",
    "              alpha: 2.0\n",
    "              beta: 4.0\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "\n",
    "        deepmac_mask_estimation {\n",
    "          classification_loss {\n",
    "            weighted_sigmoid {}\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    \"\"\"\n",
    "    # Set up the configuration proto.\n",
    "    config = text_format.Parse(proto_txt, model_pb2.DetectionModel())\n",
    "\n",
    "    # Build the model from the configuration.\n",
    "    model = model_builder.build(config, is_training=True)\n",
    "    self.assertIsInstance(model, deepmac_meta_arch.DeepMACMetaArch)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.test.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
